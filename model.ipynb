{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Activation, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcec4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_gen_w_aug(train_parent_directory, test_parent_directory):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                      rotation_range = 30,  \n",
    "                                      zoom_range = 0.2, \n",
    "                                      width_shift_range=0.1,  \n",
    "                                      height_shift_range=0.1,\n",
    "                                      validation_split = 0.15)\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(train_parent_directory,\n",
    "                                                       target_size = (75,75),\n",
    "                                                       batch_size = 214,\n",
    "                                                       class_mode = 'categorical',\n",
    "                                                       subset='training')\n",
    "    \n",
    "    val_generator = train_datagen.flow_from_directory(train_parent_directory,\n",
    "                                                          target_size = (75,75),\n",
    "                                                          batch_size = 37,\n",
    "                                                          class_mode = 'categorical',\n",
    "                                                          subset = 'validation')\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(test_parent_directory,\n",
    "                                                     target_size=(75,75),\n",
    "                                                     batch_size = 37,\n",
    "                                                     class_mode = 'categorical')\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3044dff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 75, 75, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 75, 75, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 73, 73, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 73, 73, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 72, 72, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 70, 70, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 70, 70, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 78400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                1254416   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,283,107\n",
      "Trainable params: 1,283,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 3\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(75,75,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides =1))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten(input_shape=(75, 75, 3)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "Optimizer = optimizers.Adam(0.001)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=Optimizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a773de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3527 images belonging to 3 classes.\n",
      "Found 621 images belonging to 3 classes.\n",
      "Found 1785 images belonging to 3 classes.\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 528s 31s/step - loss: 1.1247 - accuracy: 0.4899 - val_loss: 0.8969 - val_accuracy: 0.4767\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 355s 21s/step - loss: 0.7853 - accuracy: 0.6796 - val_loss: 0.7691 - val_accuracy: 0.6618\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 393s 23s/step - loss: 0.5179 - accuracy: 0.8069 - val_loss: 0.5648 - val_accuracy: 0.7810\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 689s 42s/step - loss: 0.3672 - accuracy: 0.8679 - val_loss: 0.4903 - val_accuracy: 0.8406\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 408s 24s/step - loss: 0.2708 - accuracy: 0.8982 - val_loss: 0.4159 - val_accuracy: 0.8502\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 464s 27s/step - loss: 0.2313 - accuracy: 0.9195 - val_loss: 0.3700 - val_accuracy: 0.8744\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 635s 38s/step - loss: 0.1777 - accuracy: 0.9484 - val_loss: 0.3522 - val_accuracy: 0.8857\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 723s 42s/step - loss: 0.1598 - accuracy: 0.9509 - val_loss: 0.2506 - val_accuracy: 0.9066\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 488s 29s/step - loss: 0.1350 - accuracy: 0.9665 - val_loss: 0.2674 - val_accuracy: 0.9002\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 690s 42s/step - loss: 0.1250 - accuracy: 0.9691 - val_loss: 0.2333 - val_accuracy: 0.9163\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 476s 28s/step - loss: 0.1118 - accuracy: 0.9787 - val_loss: 0.2155 - val_accuracy: 0.9259\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 401s 24s/step - loss: 0.1099 - accuracy: 0.9753 - val_loss: 0.2277 - val_accuracy: 0.9195\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 404s 24s/step - loss: 0.1014 - accuracy: 0.9841 - val_loss: 0.2030 - val_accuracy: 0.9227\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 380s 22s/step - loss: 0.0943 - accuracy: 0.9850 - val_loss: 0.2004 - val_accuracy: 0.9243\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 338s 21s/step - loss: 0.0998 - accuracy: 0.9813 - val_loss: 0.2405 - val_accuracy: 0.9227\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 476s 29s/step - loss: 0.0956 - accuracy: 0.9850 - val_loss: 0.2126 - val_accuracy: 0.9291\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 511s 30s/step - loss: 0.0879 - accuracy: 0.9884 - val_loss: 0.1764 - val_accuracy: 0.9420\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 542s 32s/step - loss: 0.0830 - accuracy: 0.9895 - val_loss: 0.1964 - val_accuracy: 0.9324\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 586s 35s/step - loss: 0.0821 - accuracy: 0.9906 - val_loss: 0.1878 - val_accuracy: 0.9372\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 611s 37s/step - loss: 0.0787 - accuracy: 0.9926 - val_loss: 0.1863 - val_accuracy: 0.9388\n",
      "Test loss: 0.08893391489982605\n",
      "Test accuracy: 0.9865546226501465\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dir = os.path.join('./datasets/train/')\n",
    "test_dir = os.path.join('./datasets/test/')\n",
    "\n",
    "train_generator, validation_generator, test_generator = image_gen_w_aug(train_dir, test_dir)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "          batch_size=50,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data = validation_generator)\n",
    "\n",
    "score = model.evaluate(test_generator, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "tf.keras.models.save_model(model,'my_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b64d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# plt.plot(model.history['accuracy'], label='train acc')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# plt.plot(model.history['val_accuracy'], label='val acc')\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# plt.legend()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# plt.legend()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
